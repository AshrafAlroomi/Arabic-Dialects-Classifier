{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_celan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDzt2TsoyDcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "40f81b9e-0a16-4420-bb30-f9f2b532ebb0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVMxZcEyyEFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61c86d1d-cf4c-4771-a0e0-3dd66288bc7d"
      },
      "source": [
        "%cd drive/My\\ Drive/books"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/books\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApaMqpkJt-v9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f76d9fec-5a60-4801-9363-7f5764b2f2a7"
      },
      "source": [
        "!pip install tashaphyne\n",
        "!pip install pyarabic"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tashaphyne in /usr/local/lib/python3.6/dist-packages (0.3.4.1)\n",
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.6/dist-packages (from tashaphyne) (0.6.6)\n",
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.6/dist-packages (0.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiNjvt6oy6sW",
        "colab_type": "code",
        "outputId": "8253953f-c571-4837-d516-703dac03c006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alldata\t\t  dictionary.json  epochBIG.h5\tNaftawayh-0.1  textdata\n",
            "arabic_const.py   encoder\t   finalData\tpreText.py\n",
            "dictionary2.json  epochBIG\t   finalData2\t__pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J834Nl9BIeHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BwtMzN9xL_sl",
        "colab": {}
      },
      "source": [
        "# d='textdata/{}'\n",
        "# for file in os.listdir(\"textdata/JOR\"):\n",
        "#     if file.endswith(\".txt\"):\n",
        "#         print(os.path.join(\"textdata\", file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge5Vu1LRPhZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2p4PsdiQf1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(D):\n",
        "  f=open(D,'r',encoding='utf-8').read()\n",
        "  return f.split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTOfDzmU1QbC",
        "colab_type": "code",
        "outputId": "dfc96213-9d79-49f4-8ef4-5aefb3f44052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "from preText import Text_clean,saveFile\n",
        "finaldatadir='finalData2/'\n",
        "dic='textdata/'\n",
        "savedir='alldata/'\n",
        "for files in os.listdir(dic):\n",
        "  for txtfile in os.listdir(dic + files):\n",
        "      if txtfile.endswith(\".txt\"):\n",
        "         D = os.path.join(dic + '/' + files , txtfile)\n",
        "         l = saveFile.read_file(D)\n",
        "         #print(l[:10])\n",
        "         words = Text_clean.CleanThewordsList(l)\n",
        "         saveFile.to_text(words,'{}{}.txt'.format(finaldatadir,str(files)))\n",
        "         #print('saved = ' , str(D))\n",
        "\n",
        "             \n",
        "\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-41e01d22110d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m          \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m          \u001b[0;31m#print(l[:10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m          \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCleanThewordsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m          \u001b[0msaveFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'{}{}.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinaldatadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m          \u001b[0;31m#print('saved = ' , str(D))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/books/preText.py\u001b[0m in \u001b[0;36mCleanThewordsList\u001b[0;34m(wordsList)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordsList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mText_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmicroCleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/books/preText.py\u001b[0m in \u001b[0;36mmicroCleaning\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmicroCleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mText_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mText_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid_arabic_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/books/preText.py\u001b[0m in \u001b[0;36mreplace_char\u001b[0;34m(ss)\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[اأإآ]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ا\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[هة]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ه\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ي'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ى'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K_EpVDhRNjhu",
        "colab": {}
      },
      "source": [
        "\n",
        "# data_dict={}\n",
        "# for f in os.listdir('finalData/'):\n",
        "#   _l=saveFile.to_list('finalData/{}'.format(f))\n",
        "#   data_dict[f.split('.')[0]]=_l\n",
        "\n",
        "# all_data=[]\n",
        "# for i in data_dict.keys():\n",
        "#   all_data = all_data + data_dict[i]\n",
        "# print(len(all_data))\n",
        "# uniqeset=list(set(all_data))\n",
        "# print(len(uniqeset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rddytZkpNhZn",
        "colab": {}
      },
      "source": [
        "# from collections import Counter \n",
        "  \n",
        "# def most_frequent(List): \n",
        "#     occurence_count = Counter(List) \n",
        "#     return occurence_count.most_common(20)\n",
        "# #most_frequent(all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_CLIKpyuPLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_=[]\n",
        "y_=[]\n",
        "for f in os.listdir(finaldatadir):\n",
        "  _l=saveFile.to_list('{}{}'.format(finaldatadir,f))\n",
        "  for i in range(10,len(_l),10):\n",
        "    x_.append(_l[i-10:i])\n",
        "    y_.append(f.split('.')[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDXcujiXxB3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(x_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhR051b6vMbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras.preprocessing.text as kpt\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXSVhAsGvUO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(x_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzZqGhbDvnYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dictionary = tokenizer.word_index\n",
        "# # Let's save this out so we can use it later\n",
        "# with open('dictionary2.json', 'w') as dictionary_file:\n",
        "#     json.dump(dictionary, dictionary_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NaCDGyev5qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(x_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQtBIbmrw8cF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBiZf5YGv-TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)\n",
        "vocabulary_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmmfVB1OwyBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYdeXbEPw7DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6zHf8Smx4ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.preprocessing import LabelBinarizer\n",
        " encoder = LabelBinarizer()\n",
        " Y = encoder.fit_transform(y_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_ED-J3Xyojs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding,Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeBJyzPnxlyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocabulary_size, seq_len,output_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 10, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(40, activation='relu'))\n",
        "    model.add(Dense(output_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sInILBX4ytKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "             X, Y, test_size=0.10,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzOZze9czCRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=create_model(vocabulary_size+1,10,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsO4y_PHzgo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist=model.fit(X_train, y_train, batch_size=30, epochs=10,verbose=1,validation_data=[X_test,y_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viUxdfGb6eif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYiuogxq7Fyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdW-h7XQ7bB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsP9W_NH7bmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('model2.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('model2tok', 'wb'))\n",
        "dump(encoder, open('model2enc', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idl4b9JNIF-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dDtjzLG7gMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVdtp9np8CKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "# pad_encoded = pad_sequences([encoded_text], maxlen=10, truncating='pre')\n",
        "# pre=model.predict(pad_encoded)\n",
        "# print(pad_encoded)\n",
        "# print(encoder.inverse_transform(pre))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5nmC9vV8xAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allpre=model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP6q87he8e3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preclass=encoder.inverse_transform(allpre)\n",
        "y_true=encoder.inverse_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URg5G4ac-6mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZPt4Tw9_TY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_true,preclass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktjv5YVv_jKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "arr=confusion_matrix(y_true,preclass)\n",
        "print(arr)\n",
        "row,col = np.diag_indices(arr.shape[0])\n",
        "arr[row,col]=200\n",
        "df = pd.DataFrame(arr, index = [i for i in ['AR','EG','JOR','MOR','SA']],\n",
        "                  columns = [i for i in ['AR','EG','JOR','MOR','SA']])\n",
        "plt.figure(figsize = (15,13))\n",
        "sns.heatmap(df, annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM6h2vq7ESdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fallpre=[]\n",
        "# for c,i in enumerate(X_test):\n",
        "#   pad=pad_sequences([i], maxlen=10, truncating='pre')\n",
        "#   p=model.predict(pad)\n",
        "#   pe=encoder.inverse_transform(p)\n",
        "#   y_true = encoder.inverse_transform(y_test[c:c+1])\n",
        "#   if pe !=y_true:\n",
        "#     fallpre.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agNN_5MQGUlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fallpre[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxhFAq7fG_Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(fallpre)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI20UK9eG04t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in fallpre[80]:\n",
        "#   print(tokenizer.index_word[i] )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}